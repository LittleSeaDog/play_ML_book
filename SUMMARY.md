# Summary

* [简介](README.md)
* [1.机器学习基本概念](ji-qi-xue-xi-ji-ben-gai-nian.md)
  * [有关数据的一些术语](chapter1/you-guan-shu-ju-de-yi-xie-zhu-yu.md)
  * [机器学习中监督学习的基本任务](chapter1/ji-qi-xue-xi-zhong-jian-du-xue-xi-de-ji-ben-ren-wu.md)
* [2.Jupyter Notebook与Numpy的使用](jupyter-notebookyu-numpy-de-shi-yong.md)
  * [Jupyter Notebook与Numpy的使用](jupyter-notebookyu-numpy-de-shi-yong/jupyter-notebookyu-numpy-de-shi-yong.md)
  * [Numpy 数据基础](jupyter-notebookyu-numpy-de-shi-yong/numpy-shu-ju-ji-chu.md)
  * [其他创建numpy.array 的方法](jupyter-notebookyu-numpy-de-shi-yong/qi-ta-chuang-jian-numpy-array-de-fang-fa.md)
  * [Numpy.array 的基本操作](jupyter-notebookyu-numpy-de-shi-yong/numpyarray-de-ji-ben-cao-zuo.md)
* [3.kNN算法的学习与使用](knnsuan-fa-de-xue-xi-yu-shi-yong.md)
  * [1.KNN算法的原理介绍](knnsuan-fa-de-xue-xi-yu-shi-yong/1knnsuan-fa-de-yuan-li-jie-shao.md)
  * [2.KNN算法的一个简单实现](knnsuan-fa-de-xue-xi-yu-shi-yong/2knnsuan-fa-de-yi-ge-jian-dan-shi-xian.md)
  * [3.判断机器学习算法的性能](knnsuan-fa-de-xue-xi-yu-shi-yong/3pan-duan-ji-qi-xue-xi-suan-fa-de-xing-neng.md)
  * [4. 超参数和模型参数](knnsuan-fa-de-xue-xi-yu-shi-yong/4. 超参数和模型参数.md)
  * [5.数据归一化](knnsuan-fa-de-xue-xi-yu-shi-yong/5.数据归一化.md)
  * [6.sklearn 中使用knn算法的总结整理](knnsuan-fa-de-xue-xi-yu-shi-yong/6.sklearn 中使用knn算法的总结整理.md)
* [4.线性回归算法](线性回归算法/README.md)
  * [1.线性回归算法简介](线性回归算法/1.线性回归算法简介.md)
  * [2.简单线性回归的实现](线性回归算法/2.简单线性回归的实现.md)
  * [3.衡量线性回归算法的指标](线性回归算法/3.衡量线性回归算法的指标.md)
  * [4.最好的衡量线性回归法的指标 R Squared](线性回归算法/4.最好的衡量线性回归法的指标-R-Squared.md)
  * [5.多元线性回归](线性回归算法/5.多元线性回归.md)
  * [6.线性回归的可解性和更多思考](线性回归法/6线性回归的可解性和更多思考.md)
* [5.梯度下降法](梯度下降法/README.md)
  * [1.梯度下降法简介](梯度下降法/1.梯度下降法简介.md)
  * [2.梯度下降法模拟](梯度下降法/2.梯度下降法模拟.md)
  * [3.多元线性回归中的梯度下降法](梯度下降法/3.多元线性回归中的梯度下降法.md)
  * [4.线性回归中的梯度下降法的实现](梯度下降法/4.线性回归中的梯度下降法的实现.md)
  * [5.随机梯度下降法](梯度下降法/5.随机梯度下降法.md)
  * [6.梯度下降法的调试](梯度下降法/6.梯度下降法的调试.md)
  * [7.梯度下降法的总结](梯度下降法/7.梯度下降法的总结.md)
* [6.主成分分析法-PCA](PCA/README.md)
  * [1.PCA简介](PCA/1.PCA简介.md)
  * [2.使用梯度上升法解决PCA问题](PCA/2.使用梯度上升法解决PCA问题.md)
  * [3.主成分PCA的实现](PCA/3.主成分PCA的实现.md)
  * [4.求数据的前N个主成分](PCA/4.求数据的前N个主成分.md)
  * [5.高维数据向低维数据进行映射](PCA/5.高维数据向低维数据进行映射.md)
  * [6.sklearn中的PCA](PCA/6.sklearn中的PCA.md)
  * [7.试手MNIST数据集](PCA/试手MNIST数据集.md)
  * [8.使用PCA对数据进行降噪](PCA/使用PCA对数据进行降噪.md)
  * [9.人脸识别与特征脸](PCA/特征脸.md)
* [7.多项式回归](多项式回归/README.md)
  * [1.多项式回归简介](多项式回归/1.什么是多项式回归.md)
  * [2.scikit-learn中的多项式回归于pipeline](多项式回归/scikit-learn中的多项式回归于pipeline.md)
  * [3.过拟合与前拟合](多项式回归/过拟合与前拟合.md)
  * [4.学习曲线](多项式回归/学习曲线.md)
  * [5.验证数据集与交叉验证](多项式回归/验证数据集与交叉验证.md)
  * [6.偏差方差均衡](多项式回归/偏差方差均衡.md)
  * [7.模型正则化](多项式回归/模型正则化.md)
  * [8.LASSO](多项式回归/LASSO.md)
  * [9.L1,L2和弹性网络](多项式回归/L1,L2和弹性网络.md)
* [8.逻辑回归](逻辑回归/README.md)
  * [1.什么是逻辑回归](逻辑回归/1.什么是逻辑回归.md)
  * [2.逻辑回归的损失函数](逻辑回归/2.逻辑回归的损失函数.md)
  * [3.逻辑回归函数损失的梯度](逻辑回归/3.逻辑回归函数损失的梯度.md)
  * [4.实现逻辑回归算法](逻辑回归/4.实现逻辑回归算法.md)
  * [5.决策边界](逻辑回归/5.决策边界.md)
  * [6.在逻辑回归中使用多项式回归](逻辑回归/6.在逻辑回归中使用多项式回归.md)
  * [7.scikit-learn中的逻辑会回归](逻辑回归/7.scikit-learn中的逻辑会回归.md)
  * [8.OvR与OvO](逻辑回归/8.OvR与OvO.md)
* [9.评价分类结果](评价分类结果/README.md)
  * [9.1 准确度的陷阱和混淆矩阵](评价分类结果/9.1 准确度的陷阱和混淆矩阵.md)
  * [9.2 精准率和召回率](评价分类结果/9.2 精准率和召回率.md)
  * [9.3 实现混淆矩阵，精准率和召回率](评价分类结果/9.3 实现混淆矩阵，精准率和召回率.md)
  * [9.4 F1 Score](评价分类结果/F1 Score.md)
  * [9.5 Precision-Recall的平衡](评价分类结果/9.5 Precision-Recall的平衡.md)
  * [9.6 精准率-召回率曲线](评价分类结果/9.6 精准率-召回率曲线.md)
  * [9.7 ROC曲线](评价分类结果/9.7 ROC曲线.md)
  * [9.8 多分类问题中的混淆矩阵](评价分类结果/9.8 多分类问题中的混淆矩阵.md)
* [10.支撑向量机 SVM](支撑向量机SVM/README.md)
  * [11.1 什么是SVM](支撑向量机SVM/11.1 什么是SVM.md)
  * [11.2 SVM背后的最优化问题](支撑向量机SVM/11.2 SVM背后的最优化问题.md)
  * [11.3 Soft Margin SVM](支撑向量机SVM/11.3 Soft Margin SVM.md)
  * [11.4 scikit-learn中的SVM](支撑向量机SVM/11.4 scikit-learn中的SVM.md)
  * [11.5 SVM中使用多项式特征和核函数](支撑向量机SVM/11.5 SVM中使用多项式特征和核函数.md)
  * [11.6 到底什么是核函数](支撑向量机SVM/11.6 到底什么是核函数.md)
  * [11.7 RBF核函数](支撑向量机SVM/11.7 RBF核函数.md)
  * [11.8 RBF核函数中的gamma](支撑向量机SVM/11.8 RBF核函数中的gamma.md)
  * [11.9 SVM思想解决回归问题](支撑向量机SVM/11.9 SVM思想解决回归问题.md)
* [11.决策树](11jue-ce-shu.md)
  * [12.1 什么是决策树](121-shi-yao-shi-jue-ce-shu.md)
  * [12.2 信息熵](122-xin-xi-shang.md)
  * [12.3 使用信息熵寻找最优划分](123-shi-yong-xin-xi-shang-xun-zhao-zui-you-hua-fen.md)
  * [12.4 基尼系数](124-ji-ni-xi-shu.md)
  * [CRAT 与决策树中的超参数](crat-yu-jue-ce-shu-zhong-de-chao-can-shu.md)
  * [12.6 决策树解决回归问题](126-jue-ce-shu-jie-jue-hui-gui-wen-ti.md)
  * [12.7 决策树的局限性](127-jue-ce-shu-de-ju-xian-xing.md)
* [13.集成学习和随机森林](13ji-cheng-xue-xi-he-sui-ji-sen-lin.md)
  * [13.1 什么是集成学习](131-shi-yao-shi-ji-cheng-xue-xi.md)
  * [13.2 Softvoting Classifier](132-softvoting-classifier.md)
  * [13.3 Bagging and Pasting](133-bagging-and-pasting.md)

